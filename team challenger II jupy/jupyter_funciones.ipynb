{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/ima/herraa.jpg\" alt=\"Imagen creada con inteligencia artificial y editada con Microsoft Paint\" style=\"border-radius: 15px;\">\n",
    "\n",
    "*Imagen creada con inteligencia artificial y editada con Microsoft Paint*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BIBLIOTECAS USADAS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from scipy.stats import f_oneway \n",
    "import inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASETS DE PRUEBA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('./data/datasets/lifesat_full.csv', sep=',')\n",
    "df2 = pd.read_csv('./data/datasets/pima_indians.csv', sep=',') #Target 'class'\n",
    "df3 = pd.read_csv('./data/datasets/temps.csv', sep=',')\n",
    "df4 = pd.read_csv('./data/datasets/titanic.csv', sep=',') #Target 'alive'\n",
    "df5 = pd.read_csv('./data/datasets/CarPrice_Assignment.csv', sep=',') # target 'Price'... o eso creo.  \n",
    "df6 = pd.read_csv('./data/datasets/bank-full.csv', sep=';') #El target parce que es 'y'  \n",
    "df7 = pd.read_csv('./data/datasets/dataset_viajes_jun23.csv', sep=',') #El target, 'aircompany' por ejemplo.  \n",
    "df8 = pd.read_csv('./data/datasets/CarPrice_Assignment_manipu.csv', sep=',', encoding='latin1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcion: get_features_num_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_num_classification(df, target_col, p_value= 0.05): \n",
    "    columnas_num= [] \n",
    "    columnas_validas= []\n",
    "    #limite = 1- p_value #No stoy seguro si hacerlo asi o directamente p_value\n",
    "\n",
    "    df_name = [nombre for nombre, valor in globals().items() if valor is df][0] #Con esto convierto el nombre del dataframe en una variable\n",
    "\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        print(f\"{df_name} es un DataFrame\")\n",
    "    else:\n",
    "        print(f\"El primer termino introducido no es un dataframe, repase la llamada a la función\")\n",
    "        return \n",
    "\n",
    "    if target_col not in df.columns:\n",
    "        print(f\"{target_col} no es una columna del dataframe df\")\n",
    "        return\n",
    "    \n",
    "    tipos_validos = ['category', 'int64', 'bool', 'object']\n",
    "    tipo_columna = df[target_col].dtype\n",
    "    if tipo_columna not in tipos_validos:\n",
    "        print(f\"La columna '{target_col}' no es categórica ni discreta, revisa la llamada a la funcion.\")\n",
    "        return \n",
    "    \n",
    "    if pd.api.types.is_integer_dtype(df[target_col]) and df[target_col].nunique() >= 15: # Este \"15\" es el maximo a partir del cual avisa de la alta cardinalidad.\n",
    "        print(f\"¡OJO!.. La columna '{target_col}' tiene alta cardinalidad (> 15 categorías).\")\n",
    "    \n",
    "    columnas_pre_num = df.select_dtypes(include=['number']).columns.tolist() \n",
    "    columnas_num= [] \n",
    "    \n",
    "    for columna_numericas in columnas_pre_num:\n",
    "        if columna_numericas != target_col: #Con esto nos aseguramos de no incluir el target.\n",
    "            columnas_num.append(columna_numericas)\n",
    "        elif columna_numericas == target_col:\n",
    "            print(\"La columna objetivo no ha sido incluida en la lista.\")\n",
    "    \n",
    "    if any(df[column].isnull().any() for column in columnas_num):\n",
    "        print(\"ALGUNA DE SUS COLUMNAS NUMÉRICAS TIENE DATOS FALTANTES O ERRÓNEOS, LIMPIE SU DATAFRAME ANTES DE CONTINUAR\")\n",
    "        return\n",
    "    \n",
    "    for columna in columnas_num:\n",
    "        grupos = []\n",
    "        for categoria in df[target_col].unique():\n",
    "            grupos.append(df[columna][df[target_col] == categoria])\n",
    "    \n",
    "        anova_result = f_oneway(*grupos)\n",
    "        if anova_result.pvalue >= p_value: #posiblemnte sea oportuno usar 'limite'\n",
    "            columnas_validas.append(columna)\n",
    "\n",
    "\n",
    "    cantidad_elementos = len(columnas_validas)\n",
    "    if cantidad_elementos == 0:\n",
    "        print(\"NO HAY COLUMNAS QUE CUMPLAN LOS REQUISITOS\")\n",
    "        return\n",
    "    if cantidad_elementos == 1:\n",
    "        print(\"Solo una columna cumple los requisitos:\")\n",
    "        print(f\"El valor de pvalue es {anova_result.pvalue}\")\n",
    "        return columnas_validas\n",
    "    if cantidad_elementos > 1:\n",
    "        print(\"Las columnas que cumplen requisitos son:\")\n",
    "        return columnas_validas\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPROBACIONES: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El primer termino introducido no es un dataframe, repase la llamada a la función\n"
     ]
    }
   ],
   "source": [
    "no_df = [\"esto\", \"es\", \"solo\", 1, \"ejemplo\"] #Para comprobar si reconoce sin fallos lo que no son dataframe hemos hecho esto \n",
    "get_features_num_classification(no_df, 'target', p_value= 0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df2 es un DataFrame\n",
      "La columna 'mass' no es categórica ni discreta, revisa la llamada a la funcion.\n"
     ]
    }
   ],
   "source": [
    "get_features_num_classification(df2, 'mass', p_value= 0.05) #'mass' es una columna de float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df2 es un DataFrame\n",
      "La columna objetivo no ha sido incluida en la lista.\n",
      "Solo una columna cumple los requisitos:\n",
      "El valor de pvalue es 2.2099754606650332e-11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['pres']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_features_num_classification(df2, 'class', p_value= 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df5 es un DataFrame\n",
      "La columna 'price' no es categórica ni discreta, revisa la llamada a la funcion.\n"
     ]
    }
   ],
   "source": [
    "get_features_num_classification(df5, 'price', p_value= 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df7 es un DataFrame\n",
      "NO HAY COLUMNAS QUE CUMPLAN LOS REQUISITOS\n"
     ]
    }
   ],
   "source": [
    "get_features_num_classification(df7, 'aircompany', p_value= 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df6 es un DataFrame\n",
      "NO HAY COLUMNAS QUE CUMPLAN LOS REQUISITOS\n"
     ]
    }
   ],
   "source": [
    "get_features_num_classification(df6, 'y', p_value= 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df4 es un DataFrame\n",
      "Solo una columna cumple los requisitos:\n",
      "El valor de pvalue es 6.120189341921873e-15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sibsp']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_features_num_classification(df4, 'alive', p_value= 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df8 es un DataFrame\n",
      "ALGUNA DE SUS COLUMNAS NUMÉRICAS TIENE DATOS FALTANTES O ERRÓNEOS, LIMPIE SU DATAFRAME ANTES DE CONTINUAR\n"
     ]
    }
   ],
   "source": [
    "get_features_num_classification(df8, 'fueltype', p_value= 0.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
